# QA PROMPTS

_This repository contains the code used for automatic **argument quality assessment**. It includes tools for error analysis, result visualization, and experimentation with different prompt variants._

## 📁 Repository Structure

```
QA_PROMPTS/
│
├── data/
├── error_analysis_plots/
├── evaluation/
├── model_responses/
├── prompting/
├── analyze_results_not_binary.py
├── analyze_results.py
├── dataset_division.py
├── dataset.csv
├── error_analysis.py
├── evaluation_ft.py
├── evaluation.py
├── fine_tunning.py
├── Logger.py
├── model_1by1.py
├── model_ft.py
├── model.py
├── requirements.txt
└── README.md
```

## 🚀 Usage

1. **Install dependencies**:

```bash
pip install -r requirements.txt
```
