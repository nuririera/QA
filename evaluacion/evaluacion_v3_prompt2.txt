Esquemas disponibles:
1: binary_good_bad
2: ternary_bad_medium_good
3: binary_effective_ineffective
4: numeric_1_to_5
Selecciona el esquema de etiquetas (1-4): Usando esquema: binary_good_bad
Archivos de respuesta de modelo disponibles:
1: model_responses_2025-06-20-12-26.json
2: model_responses_2025-06-26-20-35.json
3: model_responses_v1.json
4: model_responses_v2.json
5: model_responses_v3.json
6: model_responses_v4.json
Selecciona el número del archivo que quieres evaluar: 
=== Número de ejecuciones cargadas: 5 ===
=== Número de argumentos por ejecución: 130 ===

--- EVALUACIÓN DE LA EJECUCIÓN 1 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            40.00    37.00
1            15.00    38.00

Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.52      0.61        77
           1       0.51      0.72      0.59        53

    accuracy                           0.60       130
   macro avg       0.62      0.62      0.60       130
weighted avg       0.64      0.60      0.60       130


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            31.00    44.00
1            24.00    31.00

Classification Report:
              precision    recall  f1-score   support

           0       0.56      0.41      0.48        75
           1       0.41      0.56      0.48        55

    accuracy                           0.48       130
   macro avg       0.49      0.49      0.48       130
weighted avg       0.50      0.48      0.48       130


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            30.00    19.00
1            38.00    43.00

Classification Report:
              precision    recall  f1-score   support

           0       0.44      0.61      0.51        49
           1       0.69      0.53      0.60        81

    accuracy                           0.56       130
   macro avg       0.57      0.57      0.56       130
weighted avg       0.60      0.56      0.57       130


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            15.00    49.00
1             6.00    60.00

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.23      0.35        64
           1       0.55      0.91      0.69        66

    accuracy                           0.58       130
   macro avg       0.63      0.57      0.52       130
weighted avg       0.63      0.58      0.52       130


--- EVALUACIÓN DE LA EJECUCIÓN 2 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            42.00    35.00
1            20.00    33.00

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.55      0.60        77
           1       0.49      0.62      0.55        53

    accuracy                           0.58       130
   macro avg       0.58      0.58      0.57       130
weighted avg       0.60      0.58      0.58       130


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            24.00    51.00
1            24.00    31.00

Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.32      0.39        75
           1       0.38      0.56      0.45        55

    accuracy                           0.42       130
   macro avg       0.44      0.44      0.42       130
weighted avg       0.45      0.42      0.42       130


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            23.00    26.00
1            30.00    51.00

Classification Report:
              precision    recall  f1-score   support

           0       0.43      0.47      0.45        49
           1       0.66      0.63      0.65        81

    accuracy                           0.57       130
   macro avg       0.55      0.55      0.55       130
weighted avg       0.58      0.57      0.57       130


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            11.00    53.00
1             9.00    57.00

Classification Report:
              precision    recall  f1-score   support

           0       0.55      0.17      0.26        64
           1       0.52      0.86      0.65        66

    accuracy                           0.52       130
   macro avg       0.53      0.52      0.45       130
weighted avg       0.53      0.52      0.46       130


--- EVALUACIÓN DE LA EJECUCIÓN 3 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            34.00    43.00
1            18.00    35.00

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.44      0.53        77
           1       0.45      0.66      0.53        53

    accuracy                           0.53       130
   macro avg       0.55      0.55      0.53       130
weighted avg       0.57      0.53      0.53       130


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            38.00    37.00
1            23.00    32.00

Classification Report:
              precision    recall  f1-score   support

           0       0.62      0.51      0.56        75
           1       0.46      0.58      0.52        55

    accuracy                           0.54       130
   macro avg       0.54      0.54      0.54       130
weighted avg       0.56      0.54      0.54       130


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            26.00    23.00
1            25.00    56.00

Classification Report:
              precision    recall  f1-score   support

           0       0.51      0.53      0.52        49
           1       0.71      0.69      0.70        81

    accuracy                           0.63       130
   macro avg       0.61      0.61      0.61       130
weighted avg       0.63      0.63      0.63       130


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            13.00    51.00
1             3.00    63.00

Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.20      0.33        64
           1       0.55      0.95      0.70        66

    accuracy                           0.58       130
   macro avg       0.68      0.58      0.51       130
weighted avg       0.68      0.58      0.52       130


--- EVALUACIÓN DE LA EJECUCIÓN 4 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            36.00    41.00
1            17.00    36.00

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.47      0.55        77
           1       0.47      0.68      0.55        53

    accuracy                           0.55       130
   macro avg       0.57      0.57      0.55       130
weighted avg       0.59      0.55      0.55       130


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            39.00    36.00
1            24.00    31.00

Classification Report:
              precision    recall  f1-score   support

           0       0.62      0.52      0.57        75
           1       0.46      0.56      0.51        55

    accuracy                           0.54       130
   macro avg       0.54      0.54      0.54       130
weighted avg       0.55      0.54      0.54       130


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            24.00    25.00
1            29.00    52.00

Classification Report:
              precision    recall  f1-score   support

           0       0.45      0.49      0.47        49
           1       0.68      0.64      0.66        81

    accuracy                           0.58       130
   macro avg       0.56      0.57      0.56       130
weighted avg       0.59      0.58      0.59       130


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            12.00    52.00
1             6.00    60.00

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.19      0.29        64
           1       0.54      0.91      0.67        66

    accuracy                           0.55       130
   macro avg       0.60      0.55      0.48       130
weighted avg       0.60      0.55      0.49       130


--- EVALUACIÓN DE LA EJECUCIÓN 5 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            43.00    34.00
1            15.00    38.00

Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.56      0.64        77
           1       0.53      0.72      0.61        53

    accuracy                           0.62       130
   macro avg       0.63      0.64      0.62       130
weighted avg       0.65      0.62      0.63       130


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            29.00    46.00
1            21.00    34.00

Classification Report:
              precision    recall  f1-score   support

           0       0.58      0.39      0.46        75
           1       0.42      0.62      0.50        55

    accuracy                           0.48       130
   macro avg       0.50      0.50      0.48       130
weighted avg       0.51      0.48      0.48       130


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0            22.00    27.00
1            33.00    48.00

Classification Report:
              precision    recall  f1-score   support

           0       0.40      0.45      0.42        49
           1       0.64      0.59      0.62        81

    accuracy                           0.54       130
   macro avg       0.52      0.52      0.52       130
weighted avg       0.55      0.54      0.54       130


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             7.00    57.00
1             7.00    59.00

Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.11      0.18        64
           1       0.51      0.89      0.65        66

    accuracy                           0.51       130
   macro avg       0.50      0.50      0.41       130
weighted avg       0.50      0.51      0.42       130


--- ANÁLISIS DE VARIABILIDAD ENTRE ARGUMENTOS (ACROSS ARGUMENTS) ---

 === ANÁLISIS AGREGADO EN MÚLTIPLES EJECUCIONES ===


 --- COGENCY ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0            39.00    38.00
1            17.00    36.00

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             3.46     3.46
1             1.90     1.90

 --- EFFECTIVENESS ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0            32.20    42.80
1            23.20    31.80

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             5.64     5.64
1             1.17     1.17

 --- REASONABLENESS ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0            25.00    24.00
1            31.00    50.00

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.83     2.83
1             4.34     4.34

 --- OVERALL ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0            11.60    52.40
1             6.20    59.80

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.65     2.65
1             1.94     1.94

 === REPORTE PROMEDIO DE CLASIFICACIÓN ===

 --- COGENCY ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.70      0.51      0.59        77
1                         0.49      0.68      0.57        53
macro avg                 0.59      0.59      0.58       130
weighted avg              0.61      0.58      0.58       130

 --- EFFECTIVENESS ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.58      0.43      0.49        75
1                         0.43      0.58      0.49        55
macro avg                 0.50      0.50      0.49       130
weighted avg              0.51      0.49      0.49       130

 --- REASONABLENESS ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.45      0.51      0.48        49
1                         0.68      0.62      0.64        81
macro avg                 0.56      0.56      0.56       130
weighted avg              0.59      0.58      0.58       130

 --- OVERALL ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.65      0.18      0.28        64
1                         0.53      0.91      0.67        66
macro avg                 0.59      0.54      0.48       130
weighted avg              0.59      0.55      0.48       130

--- ANÁLISIS DE VARIABILIDAD ENTRE EJECUCIONES (ACROSS RUNS) ---

 --- RESULTADOS DE VARIABILIDAD ENTRE EJECUCIONES ---


 --- VARIABILIDAD EN COGENCY ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.28
Argumentos con desacuerdo: 80 / 130 (61.54%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 57.69%
Precisión media por argumento: 57.69%
Desviación estándar de precisión por argumento: 34.16%

Distribución de argumentos según tasa de aciertos en runs:
- 35 argumentos (26.92%) acertados en 100% de los runs.
- 43 argumentos (33.08%) con entre 50% y 99% de aciertos.
- 52 argumentos (40.00%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[1 0 0 1 1]
 [0 0 1 1 0]
 [0 1 0 0 0]
 [0 0 1 1 0]
 [1 0 1 0 0]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [0 0 0 0 0]
 [1 0 1 0 0]
 [0 0 1 1 1]
 [0 0 0 0 0]
 [1 1 1 0 1]
 [0 0 0 0 0]
 [0 0 0 0 0]
 [0 0 1 1 1]
 [1 1 1 1 1]
 [0 0 1 0 1]
 [1 1 1 1 1]
 [0 1 0 1 1]
 [0 0 0 0 0]
 [1 1 1 1 0]
 [0 0 0 0 0]
 [0 0 0 0 0]
 [0 0 1 0 1]
 [1 1 1 1 1]
 [0 1 0 0 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 0 0 1 0]
 [1 0 1 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 0 1 0]
 [1 1 0 1 0]
 [0 1 0 1 1]
 [1 0 1 0 1]
 [0 0 1 0 0]
 [1 1 1 1 1]
 [1 0 0 1 0]
 [0 1 0 0 1]
 [1 1 1 1 1]
 [0 0 1 0 0]
 [0 0 0 0 0]
 [0 1 1 1 0]
 [1 1 0 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [0 0 1 0 1]
 [1 1 1 1 1]
 [1 0 1 1 0]
 [0 1 0 0 0]
 [0 0 1 0 0]
 [1 0 1 1 1]
 [1 1 1 1 1]
 [0 0 1 1 1]
 [1 1 1 1 1]
 [0 0 0 1 1]
 [0 0 0 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 0 1 0 0]
 [0 0 1 0 1]
 [0 0 0 0 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [0 0 0 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [0 0 0 0 0]
 [0 1 1 1 1]
 [0 0 0 0 0]
 [0 0 0 1 0]
 [0 0 0 0 0]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 0 1 0]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [0 0 0 0 0]
 [0 0 1 1 0]
 [1 0 0 1 0]
 [1 0 0 0 1]
 [1 0 1 0 0]
 [1 1 1 0 1]
 [0 0 0 0 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 0 1 1 0]
 [1 0 0 0 0]
 [0 1 0 1 1]
 [0 1 1 0 0]
 [1 1 1 1 0]
 [1 1 1 0 1]
 [1 1 1 1 1]
 [0 0 0 0 0]
 [0 1 1 1 1]
 [1 1 1 0 0]
 [1 0 0 0 1]
 [1 0 0 1 1]
 [0 0 0 0 0]
 [1 1 0 1 1]
 [1 1 1 1 0]
 [1 1 1 0 0]
 [1 0 0 0 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 0 0 0 1]
 [1 0 0 1 1]
 [1 1 0 0 0]
 [0 1 0 0 0]
 [1 1 1 1 0]
 [1 0 1 1 1]
 [1 0 1 1 0]
 [1 1 0 0 0]
 [0 0 1 0 0]
 [1 0 0 0 1]
 [0 1 1 1 0]
 [1 0 0 1 1]
 [0 0 0 0 0]
 [1 1 1 1 0]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 60.00%

 --- VARIABILIDAD EN EFFECTIVENESS ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.37
Argumentos con desacuerdo: 106 / 130 (81.54%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 49.23%
Precisión media por argumento: 49.23%
Desviación estándar de precisión por argumento: 28.73%

Distribución de argumentos según tasa de aciertos en runs:
- 12 argumentos (9.23%) acertados en 100% de los runs.
- 48 argumentos (36.92%) con entre 50% y 99% de aciertos.
- 70 argumentos (53.85%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[0 1 1 0 0]
 [1 1 0 0 1]
 [1 0 1 1 1]
 [1 1 1 0 1]
 [0 1 0 1 1]
 [0 0 0 0 0]
 [1 0 0 1 0]
 [1 1 1 1 1]
 [0 1 0 1 1]
 [1 1 0 1 0]
 [1 1 1 1 1]
 [0 0 0 1 1]
 [1 0 1 1 1]
 [1 1 1 1 1]
 [0 1 0 0 0]
 [1 1 1 1 1]
 [1 1 0 1 0]
 [1 1 1 1 1]
 [1 0 1 0 0]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 0 1 0]
 [0 1 1 0 0]
 [1 0 1 1 0]
 [0 1 1 1 1]
 [0 0 1 0 1]
 [1 1 1 0 1]
 [1 1 1 0 1]
 [1 1 0 0 1]
 [1 1 1 1 0]
 [0 0 0 0 1]
 [0 0 1 0 1]
 [0 0 1 0 1]
 [1 0 1 0 1]
 [0 1 0 1 0]
 [1 1 0 1 1]
 [0 0 0 0 1]
 [0 1 1 0 1]
 [1 0 1 1 1]
 [0 0 1 1 1]
 [1 1 0 1 1]
 [1 1 1 1 1]
 [1 0 0 0 1]
 [1 0 1 0 0]
 [0 0 1 0 1]
 [1 0 0 0 0]
 [0 0 0 0 1]
 [1 1 0 1 0]
 [1 1 1 1 0]
 [1 0 0 0 0]
 [1 1 0 1 1]
 [1 0 1 1 1]
 [1 1 0 1 1]
 [0 1 0 0 0]
 [0 0 0 0 0]
 [1 1 0 0 0]
 [0 1 0 0 0]
 [1 1 1 0 0]
 [1 1 1 0 1]
 [0 0 0 0 0]
 [0 1 0 0 0]
 [0 1 1 0 1]
 [0 1 0 1 0]
 [0 0 0 0 0]
 [1 1 0 1 1]
 [1 1 0 1 0]
 [1 1 1 1 1]
 [1 1 0 0 0]
 [0 0 1 1 0]
 [1 1 1 1 0]
 [1 1 1 0 0]
 [0 0 1 1 1]
 [0 0 0 0 0]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [1 1 0 0 0]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [1 1 0 1 1]
 [0 0 1 0 0]
 [1 0 0 1 0]
 [0 0 1 0 1]
 [1 1 1 1 1]
 [1 1 1 1 0]
 [1 1 1 0 1]
 [1 1 0 0 1]
 [0 1 1 0 1]
 [0 1 1 1 0]
 [0 1 0 1 1]
 [0 0 0 1 0]
 [1 1 1 1 1]
 [1 0 0 0 1]
 [1 1 1 1 1]
 [1 1 0 0 1]
 [0 1 1 1 1]
 [1 0 1 0 0]
 [1 0 0 1 1]
 [1 1 1 0 1]
 [1 1 0 1 1]
 [1 1 0 0 1]
 [0 0 0 0 1]
 [1 0 0 0 0]
 [0 0 0 1 1]
 [0 1 1 1 0]
 [0 1 1 0 0]
 [1 1 1 1 1]
 [0 0 1 0 0]
 [0 1 0 0 1]
 [0 0 0 0 1]
 [0 1 1 1 0]
 [1 0 0 0 0]
 [1 1 0 1 1]
 [0 1 1 1 0]
 [1 1 1 1 1]
 [0 0 1 1 1]
 [1 0 1 0 1]
 [0 1 0 0 1]
 [0 1 0 0 0]
 [0 1 0 0 1]
 [0 0 1 1 1]
 [1 1 0 1 1]
 [0 1 1 1 0]
 [1 0 0 0 1]
 [0 1 1 0 0]
 [1 1 1 1 1]
 [0 0 0 1 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 46.15%

 --- VARIABILIDAD EN REASONABLENESS ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.38
Argumentos con desacuerdo: 110 / 130 (84.62%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 57.69%
Precisión media por argumento: 57.69%
Desviación estándar de precisión por argumento: 26.91%

Distribución de argumentos según tasa de aciertos en runs:
- 15 argumentos (11.54%) acertados en 100% de los runs.
- 65 argumentos (50.00%) con entre 50% y 99% de aciertos.
- 50 argumentos (38.46%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[1 1 1 0 1]
 [1 0 1 1 0]
 [0 0 0 1 0]
 [0 1 0 1 1]
 [0 1 0 1 1]
 [1 1 0 1 1]
 [0 1 1 1 0]
 [0 0 0 1 0]
 [1 0 0 0 0]
 [0 1 1 1 0]
 [0 1 0 1 1]
 [0 1 0 1 0]
 [0 1 0 0 0]
 [0 0 0 0 0]
 [1 0 1 1 0]
 [1 1 1 1 1]
 [0 1 1 0 0]
 [0 1 1 1 1]
 [0 0 1 1 1]
 [1 0 0 0 1]
 [1 1 1 1 1]
 [0 1 0 0 1]
 [0 1 0 1 1]
 [1 1 0 0 0]
 [1 1 1 1 1]
 [0 1 0 1 0]
 [1 1 1 1 1]
 [1 1 0 1 0]
 [1 1 1 1 1]
 [0 0 1 1 1]
 [0 0 1 1 1]
 [0 1 1 1 1]
 [1 1 0 1 0]
 [0 1 1 0 0]
 [0 0 0 0 0]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 1 1 0 1]
 [1 1 1 1 0]
 [0 1 1 1 1]
 [0 1 1 0 0]
 [1 1 0 0 0]
 [1 1 1 1 0]
 [0 1 1 0 1]
 [1 1 1 1 1]
 [0 1 0 0 1]
 [0 1 1 1 1]
 [0 1 1 0 1]
 [0 1 1 0 0]
 [1 1 1 0 1]
 [0 1 0 1 1]
 [0 0 1 1 0]
 [0 0 1 0 0]
 [1 1 1 1 1]
 [0 0 1 1 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 0 1 0 1]
 [1 0 0 0 1]
 [0 0 0 0 1]
 [1 1 0 1 1]
 [1 1 1 0 1]
 [1 0 0 0 0]
 [1 0 1 0 1]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [0 1 1 0 1]
 [0 0 0 1 0]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [1 1 0 1 1]
 [1 1 1 0 1]
 [1 0 1 1 1]
 [1 0 0 0 0]
 [1 1 0 0 0]
 [1 0 1 1 1]
 [0 1 1 1 1]
 [0 1 0 1 0]
 [0 0 0 0 0]
 [1 1 1 1 1]
 [0 1 0 1 1]
 [0 1 0 1 1]
 [0 1 1 1 1]
 [1 1 1 0 1]
 [1 1 1 1 0]
 [0 0 1 0 1]
 [1 0 0 1 0]
 [1 1 1 0 0]
 [0 0 1 0 0]
 [1 0 0 0 0]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [0 0 0 0 0]
 [0 0 1 0 0]
 [1 0 1 1 0]
 [0 0 1 0 0]
 [1 0 1 0 0]
 [0 0 1 1 1]
 [0 1 1 1 0]
 [0 0 0 1 0]
 [0 0 1 1 0]
 [0 0 1 1 1]
 [1 1 0 0 0]
 [0 1 0 0 1]
 [0 1 1 0 0]
 [0 1 1 1 1]
 [0 0 0 1 0]
 [0 0 1 0 0]
 [1 1 0 1 1]
 [1 0 0 1 1]
 [0 1 0 1 0]
 [1 1 1 0 1]
 [1 1 1 1 1]
 [0 0 1 1 0]
 [1 0 0 0 1]
 [0 0 0 1 1]
 [1 1 0 0 0]
 [0 0 0 1 1]
 [1 0 1 1 1]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 0 0 1 0]
 [0 0 1 0 0]
 [1 0 1 1 1]
 [0 1 1 0 0]
 [0 0 1 0 1]
 [0 1 0 0 0]
 [1 1 1 0 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 61.54%

 --- VARIABILIDAD EN OVERALL ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.20
Argumentos con desacuerdo: 59 / 130 (45.38%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 54.92%
Precisión media por argumento: 54.92%
Desviación estándar de precisión por argumento: 40.25%

Distribución de argumentos según tasa de aciertos en runs:
- 41 argumentos (31.54%) acertados en 100% de los runs.
- 30 argumentos (23.08%) con entre 50% y 99% de aciertos.
- 59 argumentos (45.38%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[1 1 1 0 1]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 1 1 1 1]
 [0 1 0 1 1]
 [1 1 1 1 1]
 [1 1 1 1 0]
 [1 1 1 1 0]
 [1 0 1 0 1]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [1 1 0 1 1]
 [0 1 0 1 1]
 [1 0 1 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 0 0 0 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 1 0 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 1 1 1 1]
 [1 1 0 1 1]
 [1 1 1 0 1]
 [0 1 0 0 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 0 1 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 0 1 1 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [1 0 1 0 1]
 [1 0 0 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 0 0 1 1]
 [1 1 1 1 1]
 [0 1 0 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 0 1 1 1]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 1 0 1 1]
 [1 1 0 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [1 1 1 1 0]
 [1 0 1 0 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [1 0 1 1 1]
 [1 0 1 0 1]
 [1 1 1 1 1]
 [1 1 1 0 0]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [0 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [0 0 0 0 1]
 [1 1 1 1 1]
 [0 1 1 1 1]
 [0 1 1 1 1]
 [1 0 1 1 1]
 [0 0 1 0 0]
 [1 1 1 1 1]
 [1 1 0 1 1]
 [0 1 0 1 0]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 0 0 1]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [0 0 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 1]
 [1 1 1 1 0]
 [1 1 1 1 1]
 [1 1 1 0 1]
 [0 1 1 0 1]
 [1 1 1 1 0]
 [1 1 1 1 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 54.62%

--- TIEMPO TOTAL DE EJECUCIÓN DE LA EVALUACIÓN ---
Tiempo total: 4.71 segundos
