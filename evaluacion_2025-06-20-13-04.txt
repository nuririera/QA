Available model response files:
1: model_responses_2025-06-20-12-26.json
Select a file number to evaluate: === Number of runs loaded: 8 ===
=== Number of arguments per run: 49 ===

--- EVALUATION OF RUN 1 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.00   15.00]
True Good  [6.00   23.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.45      0.25      0.32        20
           1       0.61      0.79      0.69        29

    accuracy                           0.57        49
   macro avg       0.53      0.52      0.50        49
weighted avg       0.54      0.57      0.54        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.00   6.00 ]
True Good  [8.00   28.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.47      0.54      0.50        13
           1       0.82      0.78      0.80        36

    accuracy                           0.71        49
   macro avg       0.65      0.66      0.65        49
weighted avg       0.73      0.71      0.72        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   14.00]
True Good  [11.00  15.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.45      0.39      0.42        23
           1       0.52      0.58      0.55        26

    accuracy                           0.49        49
   macro avg       0.48      0.48      0.48        49
weighted avg       0.49      0.49      0.49        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [6.00   14.00]
True Good  [5.00   24.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.55      0.30      0.39        20
           1       0.63      0.83      0.72        29

    accuracy                           0.61        49
   macro avg       0.59      0.56      0.55        49
weighted avg       0.60      0.61      0.58        49


--- EVALUATION OF RUN 2 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   11.00]
True Good  [6.00   23.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.60      0.45      0.51        20
           1       0.68      0.79      0.73        29

    accuracy                           0.65        49
   macro avg       0.64      0.62      0.62        49
weighted avg       0.65      0.65      0.64        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.00   8.00 ]
True Good  [9.00   27.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.36      0.38      0.37        13
           1       0.77      0.75      0.76        36

    accuracy                           0.65        49
   macro avg       0.56      0.57      0.57        49
weighted avg       0.66      0.65      0.66        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   14.00]
True Good  [6.00   20.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.60      0.39      0.47        23
           1       0.59      0.77      0.67        26

    accuracy                           0.59        49
   macro avg       0.59      0.58      0.57        49
weighted avg       0.59      0.59      0.58        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.00   13.00]
True Good  [3.00   26.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.35      0.47        20
           1       0.67      0.90      0.76        29

    accuracy                           0.67        49
   macro avg       0.68      0.62      0.62        49
weighted avg       0.68      0.67      0.64        49


--- EVALUATION OF RUN 3 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.00   15.00]
True Good  [5.00   24.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.25      0.33        20
           1       0.62      0.83      0.71        29

    accuracy                           0.59        49
   macro avg       0.56      0.54      0.52        49
weighted avg       0.57      0.59      0.55        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.00   8.00 ]
True Good  [11.00  25.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.31      0.38      0.34        13
           1       0.76      0.69      0.72        36

    accuracy                           0.61        49
   macro avg       0.54      0.54      0.53        49
weighted avg       0.64      0.61      0.62        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   14.00]
True Good  [8.00   18.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.53      0.39      0.45        23
           1       0.56      0.69      0.62        26

    accuracy                           0.55        49
   macro avg       0.55      0.54      0.54        49
weighted avg       0.55      0.55      0.54        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [6.00   14.00]
True Good  [6.00   23.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.30      0.38        20
           1       0.62      0.79      0.70        29

    accuracy                           0.59        49
   macro avg       0.56      0.55      0.54        49
weighted avg       0.57      0.59      0.57        49


--- EVALUATION OF RUN 4 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.00   15.00]
True Good  [6.00   23.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.45      0.25      0.32        20
           1       0.61      0.79      0.69        29

    accuracy                           0.57        49
   macro avg       0.53      0.52      0.50        49
weighted avg       0.54      0.57      0.54        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.00   8.00 ]
True Good  [7.00   29.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.42      0.38      0.40        13
           1       0.78      0.81      0.79        36

    accuracy                           0.69        49
   macro avg       0.60      0.60      0.60        49
weighted avg       0.69      0.69      0.69        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.00   16.00]
True Good  [13.00  13.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.35      0.30      0.33        23
           1       0.45      0.50      0.47        26

    accuracy                           0.41        49
   macro avg       0.40      0.40      0.40        49
weighted avg       0.40      0.41      0.40        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [8.00   12.00]
True Good  [4.00   25.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.40      0.50        20
           1       0.68      0.86      0.76        29

    accuracy                           0.67        49
   macro avg       0.67      0.63      0.63        49
weighted avg       0.67      0.67      0.65        49


--- EVALUATION OF RUN 5 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [6.00   14.00]
True Good  [8.00   21.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.43      0.30      0.35        20
           1       0.60      0.72      0.66        29

    accuracy                           0.55        49
   macro avg       0.51      0.51      0.50        49
weighted avg       0.53      0.55      0.53        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [4.00   9.00 ]
True Good  [8.00   28.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.33      0.31      0.32        13
           1       0.76      0.78      0.77        36

    accuracy                           0.65        49
   macro avg       0.55      0.54      0.54        49
weighted avg       0.64      0.65      0.65        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [12.00  11.00]
True Good  [8.00   18.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.60      0.52      0.56        23
           1       0.62      0.69      0.65        26

    accuracy                           0.61        49
   macro avg       0.61      0.61      0.61        49
weighted avg       0.61      0.61      0.61        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.00   13.00]
True Good  [6.00   23.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.54      0.35      0.42        20
           1       0.64      0.79      0.71        29

    accuracy                           0.61        49
   macro avg       0.59      0.57      0.57        49
weighted avg       0.60      0.61      0.59        49


--- EVALUATION OF RUN 6 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [8.00   12.00]
True Good  [5.00   24.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.62      0.40      0.48        20
           1       0.67      0.83      0.74        29

    accuracy                           0.65        49
   macro avg       0.64      0.61      0.61        49
weighted avg       0.65      0.65      0.63        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [6.00   7.00 ]
True Good  [6.00   30.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.46      0.48        13
           1       0.81      0.83      0.82        36

    accuracy                           0.73        49
   macro avg       0.66      0.65      0.65        49
weighted avg       0.73      0.73      0.73        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [11.00  12.00]
True Good  [9.00   17.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.55      0.48      0.51        23
           1       0.59      0.65      0.62        26

    accuracy                           0.57        49
   macro avg       0.57      0.57      0.56        49
weighted avg       0.57      0.57      0.57        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   11.00]
True Good  [7.00   22.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.56      0.45      0.50        20
           1       0.67      0.76      0.71        29

    accuracy                           0.63        49
   macro avg       0.61      0.60      0.60        49
weighted avg       0.62      0.63      0.62        49


--- EVALUATION OF RUN 7 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.00   13.00]
True Good  [6.00   23.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.54      0.35      0.42        20
           1       0.64      0.79      0.71        29

    accuracy                           0.61        49
   macro avg       0.59      0.57      0.57        49
weighted avg       0.60      0.61      0.59        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [4.00   9.00 ]
True Good  [7.00   29.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.36      0.31      0.33        13
           1       0.76      0.81      0.78        36

    accuracy                           0.67        49
   macro avg       0.56      0.56      0.56        49
weighted avg       0.66      0.67      0.66        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   14.00]
True Good  [9.00   17.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.39      0.44        23
           1       0.55      0.65      0.60        26

    accuracy                           0.53        49
   macro avg       0.52      0.52      0.52        49
weighted avg       0.53      0.53      0.52        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.00   13.00]
True Good  [4.00   25.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.35      0.45        20
           1       0.66      0.86      0.75        29

    accuracy                           0.65        49
   macro avg       0.65      0.61      0.60        49
weighted avg       0.65      0.65      0.63        49


--- EVALUATION OF RUN 8 ---

 --- ANALYSIS RESULTS --- (evaluating model outputs against ground truths - SINGLE RUN)


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [6.00   14.00]
True Good  [4.00   25.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.60      0.30      0.40        20
           1       0.64      0.86      0.74        29

    accuracy                           0.63        49
   macro avg       0.62      0.58      0.57        49
weighted avg       0.62      0.63      0.60        49


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   4.00 ]
True Good  [11.00  25.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.45      0.69      0.55        13
           1       0.86      0.69      0.77        36

    accuracy                           0.69        49
   macro avg       0.66      0.69      0.66        49
weighted avg       0.75      0.69      0.71        49


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.00   14.00]
True Good  [12.00  14.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.43      0.39      0.41        23
           1       0.50      0.54      0.52        26

    accuracy                           0.47        49
   macro avg       0.46      0.46      0.46        49
weighted avg       0.47      0.47      0.47        49


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [11.00  9.00 ]
True Good  [5.00   24.00]
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.55      0.61        20
           1       0.73      0.83      0.77        29

    accuracy                           0.71        49
   macro avg       0.71      0.69      0.69        49
weighted avg       0.71      0.71      0.71        49


--- VARIABILITY ANALYSIS ACROSS ARGUMENTS ---

 === AGGREGATED ANALYSIS ACROSS MULTIPLE RUNS ===


 === CONFUSION MATRICES ACROSS RUNS ===

 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [6.38   13.62]
True Good  [5.75   23.25]

 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [5.62   7.38 ]
True Good  [8.38   27.62]

 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [9.38   13.62]
True Good  [9.50   16.50]

 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
               Predicted
               Bad     Good
True Bad   [7.62   12.38]
True Good  [5.00   24.00]

 === CLASSIFICATION REPORT ACROSS RUNS ===

 --- COGENCY ---
                precision    recall  f1-score   support
-------------------------------------------------------
0                    0.52      0.32      0.39        20
1                    0.63      0.80      0.71        29

accuracy                                           0.60
macro avg            0.58      0.56      0.55        49
weighted avg         0.59      0.60      0.58        49

 --- EFFECTIVENESS ---
                precision    recall  f1-score   support
-------------------------------------------------------
0                    0.40      0.43      0.41        13
1                    0.79      0.77      0.78        36

accuracy                                           0.68
macro avg            0.60      0.60      0.59        49
weighted avg         0.69      0.68      0.68        49

 --- REASONABLENESS ---
                precision    recall  f1-score   support
-------------------------------------------------------
0                    0.50      0.41      0.45        23
1                    0.55      0.63      0.59        26

accuracy                                           0.53
macro avg            0.52      0.52      0.52        49
weighted avg         0.53      0.53      0.52        49

 --- OVERALL ---
                precision    recall  f1-score   support
-------------------------------------------------------
0                    0.60      0.38      0.46        20
1                    0.66      0.83      0.73        29

accuracy                                           0.65
macro avg            0.63      0.60      0.60        49
weighted avg         0.64      0.65      0.62        49

--- VARIABILITY ANALYSIS ACROSS RUNS ---

 --- ANALYSIS RESULTS --- (analyzing variability across multiple runs)


 --- VARIABILITY IN COGENCY ---
Mean standard deviation per argument: 0.16
Arguments with disagreement: 19 / 49 (38.78%)

(rows = arguments, columns = runs):
[[1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 1 0 0 0 1 0 1]
 [1 0 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 1 0 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 1 0 1 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [0 0 1 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 1 0 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 0 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 0 1 1 0 0 1]
 [1 0 1 1 1 0 1 0]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 0 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [1 1 0 1 0 0 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 0 1 1 0 1 1 1]
 [1 1 1 1 0 0 0 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 0 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 1 1 1]
 [1 0 1 0 1 1 1 1]
 [0 0 0 1 0 0 0 0]
 [1 1 1 0 1 0 0 1]
 [1 1 1 1 1 1 1 1]]

 --- VARIABILITY IN EFFECTIVENESS ---
Mean standard deviation per argument: 0.28
Arguments with disagreement: 31 / 49 (63.27%)

(rows = arguments, columns = runs):
[[1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 0 1 1 1 0 1 0]
 [0 1 0 0 0 0 0 1]
 [1 1 1 1 1 1 1 1]
 [0 0 0 1 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 0 1 0 1 1 0]
 [0 1 1 1 1 1 1 0]
 [0 0 1 0 0 0 1 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 0 0 1 0 1 0]
 [1 1 1 1 1 1 1 1]
 [1 0 0 1 1 1 0 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 0 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 0 1 0 0 1 0]
 [1 1 1 1 1 1 1 1]
 [0 0 1 1 1 0 1 0]
 [1 0 1 1 1 1 0 1]
 [1 1 1 0 1 1 1 0]
 [0 1 0 0 1 1 0 1]
 [0 0 0 1 0 1 1 0]
 [0 0 0 1 0 1 1 1]
 [1 0 1 1 1 1 0 0]
 [1 1 1 0 1 0 0 0]
 [1 0 1 1 1 1 1 0]
 [1 0 1 1 1 1 1 1]
 [1 1 0 1 0 0 1 0]
 [0 1 1 0 1 0 1 0]
 [0 1 0 0 1 1 1 0]
 [1 1 0 1 1 0 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 1 1 1]
 [0 1 0 0 0 1 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 0 1 1 1 1 1]
 [0 1 1 0 1 1 0 0]
 [0 1 0 1 1 0 0 0]
 [1 1 1 0 0 1 0 0]
 [1 0 0 1 0 1 1 1]
 [1 1 1 1 1 1 1 1]]

 --- VARIABILITY IN REASONABLENESS ---
Mean standard deviation per argument: 0.34
Arguments with disagreement: 38 / 49 (77.55%)

(rows = arguments, columns = runs):
[[1 1 1 0 1 1 0 1]
 [1 1 1 1 1 1 1 0]
 [0 1 1 1 1 1 1 1]
 [0 1 0 0 0 0 0 0]
 [1 1 0 1 0 0 1 0]
 [1 1 0 0 0 0 1 0]
 [1 1 1 0 1 1 1 1]
 [1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 0 1 1]
 [0 0 1 0 1 1 0 1]
 [1 0 0 0 1 1 0 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 1 0 1]
 [0 0 0 1 0 1 1 0]
 [0 1 0 0 0 0 1 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 1 1 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 0 1 0 1 1]
 [0 0 1 0 1 1 1 0]
 [1 1 0 1 0 1 1 1]
 [0 1 0 1 0 1 1 0]
 [1 0 0 0 0 0 1 1]
 [0 1 1 0 0 0 0 0]
 [1 0 1 0 1 0 0 1]
 [1 1 1 0 1 1 1 1]
 [0 1 0 0 0 0 1 1]
 [0 0 0 1 0 1 0 1]
 [0 1 0 1 1 0 0 0]
 [0 1 0 1 0 1 0 0]
 [1 1 1 1 1 1 1 1]
 [1 0 0 0 0 1 0 0]
 [1 0 1 1 1 0 1 1]
 [0 0 1 0 0 1 0 0]
 [0 0 0 0 0 0 0 1]
 [0 0 0 1 0 0 0 0]
 [0 1 0 0 1 0 0 0]
 [1 0 1 1 1 0 1 0]
 [1 1 1 0 1 1 1 0]
 [1 1 1 1 1 1 1 1]
 [0 0 1 1 1 0 1 1]
 [0 1 1 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [0 1 1 1 1 0 0 0]
 [1 1 1 1 1 1 1 1]]

 --- VARIABILITY IN OVERALL ---
Mean standard deviation per argument: 0.16
Arguments with disagreement: 19 / 49 (38.78%)

(rows = arguments, columns = runs):
[[1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 1 0 0 0 0 0 0]
 [1 1 0 1 0 0 1 1]
 [1 1 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 1 1 1]
 [0 1 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 0 0 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1]
 [1 0 0 0 1 0 1 1]
 [0 1 1 0 1 0 0 0]
 [0 0 0 0 0 0 0 0]
 [1 1 1 1 1 1 1 1]
 [1 0 1 1 1 1 1 1]
 [0 0 0 0 0 0 0 0]
 [1 1 0 1 1 0 1 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 0 1 0 0 1 1 0]
 [1 1 1 1 1 0 1 0]
 [1 1 0 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 0 1 1 1 1 1 0]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [0 1 1 1 1 1 1 1]
 [0 1 1 0 1 0 0 0]
 [1 1 1 1 0 1 0 0]
 [1 1 1 1 1 0 0 1]
 [1 1 1 1 1 1 1 1]]

--- TOTAL EVALUATION EXECUTION TIME ---
Total time: 3.01 seconds
