Esquemas disponibles:
1: binary_good_bad
2: ternary_bad_medium_good
3: binary_effective_ineffective
4: numeric_1_to_5
Selecciona el esquema de etiquetas (1-4): Usando esquema: binary_good_bad
Archivos de respuesta de modelo disponibles:
1: model_responses_2025-06-27-10-59.json
2: model_responses_2025-06-27-11-38.json
3: model_responses_v1.json
4: model_responses_v2.json
5: model_responses_v3.json
6: model_responses_v4.json
Selecciona el número del archivo que quieres evaluar: 
=== Número de ejecuciones cargadas: 3 ===
=== Número de argumentos por ejecución: 23 ===

--- EVALUACIÓN DE LA EJECUCIÓN 1 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.00     9.00
1             1.00    11.00

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.18      0.29        11
           1       0.55      0.92      0.69        12

    accuracy                           0.57        23
   macro avg       0.61      0.55      0.49        23
weighted avg       0.61      0.57      0.50        23


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.00     9.00
1             0.00    12.00

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.18      0.31        11
           1       0.57      1.00      0.73        12

    accuracy                           0.61        23
   macro avg       0.79      0.59      0.52        23
weighted avg       0.78      0.61      0.53        23


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             4.00     4.00
1             4.00    11.00

Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.50      0.50         8
           1       0.73      0.73      0.73        15

    accuracy                           0.65        23
   macro avg       0.62      0.62      0.62        23
weighted avg       0.65      0.65      0.65        23


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.00     8.00
1             0.00    13.00

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        10
           1       0.62      1.00      0.76        13

    accuracy                           0.65        23
   macro avg       0.81      0.60      0.55        23
weighted avg       0.78      0.65      0.58        23


--- EVALUACIÓN DE LA EJECUCIÓN 2 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             3.00     8.00
1             0.00    12.00

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.27      0.43        11
           1       0.60      1.00      0.75        12

    accuracy                           0.65        23
   macro avg       0.80      0.64      0.59        23
weighted avg       0.79      0.65      0.60        23


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.00     9.00
1             1.00    11.00

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.18      0.29        11
           1       0.55      0.92      0.69        12

    accuracy                           0.57        23
   macro avg       0.61      0.55      0.49        23
weighted avg       0.61      0.57      0.50        23


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             4.00     4.00
1             3.00    12.00

Classification Report:
              precision    recall  f1-score   support

           0       0.57      0.50      0.53         8
           1       0.75      0.80      0.77        15

    accuracy                           0.70        23
   macro avg       0.66      0.65      0.65        23
weighted avg       0.69      0.70      0.69        23


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.00     8.00
1             0.00    13.00

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        10
           1       0.62      1.00      0.76        13

    accuracy                           0.65        23
   macro avg       0.81      0.60      0.55        23
weighted avg       0.78      0.65      0.58        23


--- EVALUACIÓN DE LA EJECUCIÓN 3 ---

 --- RESULTADOS DE EVALUACIÓN (SINGLE RUN) ---


 --- COGENCY ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             1.00    10.00
1             1.00    11.00

Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.09      0.15        11
           1       0.52      0.92      0.67        12

    accuracy                           0.52        23
   macro avg       0.51      0.50      0.41        23
weighted avg       0.51      0.52      0.42        23


 --- EFFECTIVENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             1.00    10.00
1             1.00    11.00

Classification Report:
              precision    recall  f1-score   support

           0       0.50      0.09      0.15        11
           1       0.52      0.92      0.67        12

    accuracy                           0.52        23
   macro avg       0.51      0.50      0.41        23
weighted avg       0.51      0.52      0.42        23


 --- REASONABLENESS ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             4.00     4.00
1             2.00    13.00

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.50      0.57         8
           1       0.76      0.87      0.81        15

    accuracy                           0.74        23
   macro avg       0.72      0.68      0.69        23
weighted avg       0.73      0.74      0.73        23


 --- OVERALL ---

Confusion Matrix (Actual vs Predicted):
                 0        1
0             1.00     9.00
1             0.00    13.00

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.10      0.18        10
           1       0.59      1.00      0.74        13

    accuracy                           0.61        23
   macro avg       0.80      0.55      0.46        23
weighted avg       0.77      0.61      0.50        23


--- ANÁLISIS DE VARIABILIDAD ENTRE ARGUMENTOS (ACROSS ARGUMENTS) ---

 === ANÁLISIS AGREGADO EN MÚLTIPLES EJECUCIONES ===


 --- COGENCY ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0             2.00     9.00
1             0.67    11.33

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             0.82     0.82
1             0.47     0.47

 --- EFFECTIVENESS ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0             1.67     9.33
1             0.67    11.33

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             0.47     0.47
1             0.47     0.47

 --- REASONABLENESS ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0             4.00     4.00
1             3.00    12.00

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             0.00     0.00
1             0.82     0.82

 --- OVERALL ---

Matriz de Confusión Promedio (media entre runs):

Confusion Matrix (Actual vs Predicted):
                 0        1
0             1.67     8.33
1             0.00    13.00

Desviación Estándar de la Matriz de Confusión entre runs:

Confusion Matrix (Actual vs Predicted):
                 0        1
0             0.47     0.47
1             0.00     0.00

 === REPORTE PROMEDIO DE CLASIFICACIÓN ===

 --- COGENCY ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.72      0.18      0.29        11
1                         0.56      0.94      0.70        12
macro avg                 0.64      0.56      0.50        23
weighted avg              0.64      0.58      0.50        23

 --- EFFECTIVENESS ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.72      0.15      0.25        11
1                         0.55      0.94      0.69        12
macro avg                 0.64      0.55      0.47        23
weighted avg              0.63      0.57      0.48        23

 --- REASONABLENESS ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         0.58      0.50      0.53         8
1                         0.75      0.80      0.77        15
macro avg                 0.66      0.65      0.65        23
weighted avg              0.69      0.70      0.69        23

 --- OVERALL ---
Etiqueta             precision    recall  f1-score   support
------------------------------------------------------------
0                         1.00      0.17      0.28        10
1                         0.61      1.00      0.76        13
macro avg                 0.80      0.58      0.52        23
weighted avg              0.78      0.64      0.55        23

--- ANÁLISIS DE VARIABILIDAD ENTRE EJECUCIONES (ACROSS RUNS) ---

 --- RESULTADOS DE VARIABILIDAD ENTRE EJECUCIONES ---


 --- VARIABILIDAD EN COGENCY ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.14
Argumentos con desacuerdo: 7 / 23 (30.43%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 57.97%
Precisión media por argumento: 57.97%
Desviación estándar de precisión por argumento: 41.95%

Distribución de argumentos según tasa de aciertos en runs:
- 10 argumentos (43.48%) acertados en 100% de los runs.
- 3 argumentos (13.04%) con entre 50% y 99% de aciertos.
- 10 argumentos (43.48%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[1 1 1]
 [1 1 1]
 [1 1 1]
 [0 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [0 1 1]
 [1 1 1]
 [1 1 1]
 [1 0 1]
 [1 1 0]
 [1 1 0]
 [1 0 1]
 [1 1 1]
 [1 1 1]
 [0 0 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 56.52%

 --- VARIABILIDAD EN EFFECTIVENESS ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.10
Argumentos con desacuerdo: 5 / 23 (21.74%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 56.52%
Precisión media por argumento: 56.52%
Desviación estándar de precisión por argumento: 44.43%

Distribución de argumentos según tasa de aciertos en runs:
- 10 argumentos (43.48%) acertados en 100% de los runs.
- 4 argumentos (17.39%) con entre 50% y 99% de aciertos.
- 9 argumentos (39.13%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[1 1 1]
 [1 1 1]
 [1 1 0]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 0 1]
 [1 1 1]
 [0 1 0]
 [1 1 1]
 [1 0 1]
 [1 1 1]
 [0 0 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 60.87%

 --- VARIABILIDAD EN REASONABLENESS ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.16
Argumentos con desacuerdo: 8 / 23 (34.78%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 69.57%
Precisión media por argumento: 69.57%
Desviación estándar de precisión por argumento: 36.66%

Distribución de argumentos según tasa de aciertos en runs:
- 11 argumentos (47.83%) acertados en 100% de los runs.
- 7 argumentos (30.43%) con entre 50% y 99% de aciertos.
- 5 argumentos (21.74%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[0 1 0]
 [1 0 0]
 [1 1 0]
 [0 0 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [0 0 1]
 [1 1 1]
 [0 0 0]
 [1 1 1]
 [0 0 0]
 [1 1 1]
 [0 0 0]
 [1 1 1]
 [1 1 1]
 [0 1 1]
 [1 1 1]
 [1 0 1]
 [0 1 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 78.26%

 --- VARIABILIDAD EN OVERALL ---

Variabilidad entre runs:
Media de desviación estándar por argumento: 0.06
Argumentos con desacuerdo: 3 / 23 (13.04%)

Precisión global respecto al Ground Truth (media sobre todos los runs y argumentos): 63.77%
Precisión media por argumento: 63.77%
Desviación estándar de precisión por argumento: 44.95%

Distribución de argumentos según tasa de aciertos en runs:
- 13 argumentos (56.52%) acertados en 100% de los runs.
- 2 argumentos (8.70%) con entre 50% y 99% de aciertos.
- 8 argumentos (34.78%) con menos del 50% de aciertos.

Matriz de predicciones por argumento (filas=argumentos, columnas=runs):
[[1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [0 1 1]
 [1 1 1]
 [1 1 1]
 [1 1 1]
 [0 0 1]
 [1 1 1]
 [1 1 1]
 [1 0 0]
 [1 1 1]
 [1 1 1]
 [1 1 1]]

Precisión usando la media redondeada de predicciones por argumento vs Ground Truth: 65.22%

--- TIEMPO TOTAL DE EJECUCIÓN DE LA EVALUACIÓN ---
Tiempo total: 17.62 segundos
